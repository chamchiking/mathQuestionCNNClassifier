{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenzier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#설정값\n",
    "txtPath = \"tokenized_data.txt\"\n",
    "tokenizerModelName = \"token\" #만들 .model,.vocab 파일 이름\n",
    "tokenizerPath = \"./\" + tokenizerModelName + \".model\"\n",
    "vocabSize = 24000 #최대 token의 수 제한. 만들 수 있는 token의 수보다 크게 잡을 경우 에러 뜸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTokenizerModel(txtPath, modelName, vocabSize):\n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f\"--input={txtPath} --model_prefix={modelName} --vocab_size={vocabSize + 7}\" + \n",
    "        \" --model_type=bpe\" +\n",
    "        \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "        \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "        \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "        \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "        \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "        \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokenizer 모델 생성 완료\n"
     ]
    }
   ],
   "source": [
    "makeTokenizerModel(txtPath, tokenizerModelName, vocabSize) \n",
    "print(\"tokenizer 모델 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['▁\\ue034', '부터', '▁\\ue034\\ue03d', '까지의', '▁자연수가', '▁각각', '▁하나씩', '▁적힌', '▁\\ue034\\ue03d', '장의', '▁카드에서', '▁임의로', '▁\\ue036', '장의', '▁카드를', '▁뽑을', '▁때', ',', '▁가장', '▁작은', '▁수가', '▁\\ue037', '▁일', '▁확률은', '?']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(tokenizerPath)\n",
    "textForTest = \"부터 까지의 자연수가 각각 하나씩 적힌 장의 카드에서 임의로 장의 카드를 뽑을 때, 가장 작은 수가  일 확률은?\"\n",
    "print(tokenizer.encode_as_pieces(textForTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#설정값\n",
    "embedderModelName = \"embedder.model\"\n",
    "embeddingSize = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEmbedderModel(tokenizer, txtPath, modelName, embeddingSize):\n",
    "    tokenizedQuestions = []\n",
    "    with open(txtPath, \"rt\", encoding=\"UTF8\") as txtFile:\n",
    "        txtFileLines = txtFile.readlines()\n",
    "        for question in txtFileLines:\n",
    "            tokenizedResult = tokenizer.encode_as_pieces(question)\n",
    "            if len(tokenizedResult) > 1:\n",
    "                tokenizedQuestions.append(tokenizedResult)\n",
    "    \n",
    "    model = Word2Vec(sentences=tokenizedQuestions, size=embeddingSize, window=5, min_count=5, workers=4, sg=1)\n",
    "    model.save(modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "embedder 모델 생성 완료\n"
     ]
    }
   ],
   "source": [
    "makeEmbedderModel(tokenizer, txtPath, embedderModelName, embeddingSize)\n",
    "print(\"embedder 모델 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장 embedding 및 크기 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedQuestion(tokenizer, wordEmbedder, question):\n",
    "    tokensInQuestion = tokenizer.encode_as_pieces(question)\n",
    "    embeddedResult = []\n",
    "    for token in tokensInQuestion:\n",
    "        try:\n",
    "            embeddedVector = wordEmbedder.wv.get_vector(token)\n",
    "            embeddedResult.append(embeddedVector)\n",
    "        except:\n",
    "            pass\n",
    "    return np.array(embeddedResult)\n",
    "\n",
    "def embedEntireQuestion(tokenizer, wordEmbedder, txtPath):\n",
    "    embedResult = []\n",
    "    with open(txtPath, \"rt\", encoding=\"UTF8\") as txtFile:\n",
    "        txtFileLines = txtFile.readlines()\n",
    "        for question in txtFileLines:\n",
    "            if len(question) > 1:\n",
    "                embedResult.append(embedQuestion(tokenizer, wordEmbedder, question))\n",
    "    return embedResult\n",
    "\n",
    "def getMaxEmbedLength(embedResult):\n",
    "    currentMax = -1\n",
    "    for question in embedResult:\n",
    "        if question.shape[0] > currentMax:\n",
    "            currentMax = question.shape[0]\n",
    "    return currentMax\n",
    "\n",
    "def fitVector(embedResult, embeddingSize, maxLength):\n",
    "    for i in range(len(embedResult)):\n",
    "        zeroArrayTostack = np.zeros([maxLength - embedResult[i].shape[0], embeddingSize])\n",
    "        embedResult[i] = np.vstack([embedResult[i], zeroArrayTostack])\n",
    "\n",
    "def embedAndFitQuestion(tokenizer, wordEmbedder, question, embeddingSize, lengthToFit):\n",
    "    embeddedQuestion = embedQuestion(tokenizer, wordEmbedder, question)\n",
    "    zeroArrayTostack = np.zeros([lengthToFit - embeddedQuestion.shape[0], embeddingSize])\n",
    "    return np.vstack([embeddedQuestion, zeroArrayTostack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "최장 길이 문제의 토큰 수: 154\n"
     ]
    }
   ],
   "source": [
    "#모든 문제를 읽어서 tokenize 및 word embedding 한 뒤, 최대 크기에 맞춰서 0으로 채움\n",
    "wordEmbedder = Word2Vec.load(embedderModelName)\n",
    "\n",
    "result = embedEntireQuestion(tokenizer, wordEmbedder, txtPath)\n",
    "print(\"최장 길이 문제의 토큰 수:\", getMaxEmbedLength(result))\n",
    "fitVector(result, embeddingSize, 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(160, 32)\n[[ 0.11570789 -0.6297195  -0.06389525 ... -0.83909971 -0.90536386\n  -0.57258922]\n [-0.18262972 -0.33033806  0.04562072 ... -0.37462974 -1.0022285\n  -0.70879304]\n [-0.03199902 -0.36972684 -0.00715211 ... -0.48808759 -0.82278657\n  -0.53067869]\n ...\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]\n [ 0.          0.          0.         ...  0.          0.\n   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "question = \"미분가능한 함수 에 대하여       일 때 상수 ,  에 대하여 의 값을 구하여라.\"\n",
    "question = embedAndFitQuestion(tokenizer, wordEmbedder, question, embeddingSize, 160)\n",
    "print(question.shape)\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary as summary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "validation_split = 0.2\n",
    "shuffle_dataset = True\n",
    "batch_size = 64\n",
    "random_seed = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(data.Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        super(customDataset, self).__init__()\n",
    "        \n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = 'mixedQuestion.txt'\n",
    "def bringData(file):\n",
    "    qList = []\n",
    "    yList = []\n",
    "    with open(file, 'rt', encoding=\"UTF8\") as questionFile:\n",
    "        questions = json.load(questionFile)\n",
    "    for q in questions:\n",
    "        embedded = embedAndFitQuestion(tokenizer, wordEmbedder, q['question'], embeddingSize, 160)\n",
    "        channeled = [embedded]\n",
    "        channeled = np.array(channeled)\n",
    "        qList.append(channeled)\n",
    "        parse = q['value']\n",
    "        parse = int(parse.find('1')/3)\n",
    "        #parse = [int(parse[1]), int(parse[4]),int(parse[7]),int(parse[10]),int(parse[13]),int(parse[16])]\n",
    "        yList.append(parse)\n",
    "    return qList, yList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = bringData(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.FloatTensor(x_data)\n",
    "y_data = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = customDataset(x_data, y_data)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]    \n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size = batch_size, sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size = batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class questionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(questionNet, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,16,(3,32),padding=0), nn.ReLU(),\n",
    "            nn.Conv2d(16,16,(3,1), padding=0),nn.ReLU(), #16 80 1\n",
    "            nn.Conv2d(16,64,(3,1), padding=0),nn.ReLU(), #16 80 1\n",
    "            nn.MaxPool2d(1,2), #16 40 1\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.Conv2d(64,128,(3,1), padding=0),nn.ReLU(),#64 40 1\n",
    "            nn.Conv2d(128,128,(3,1), padding=0),nn.ReLU(),#64 40 1\n",
    "            nn.MaxPool2d(1,2),                                    #64 20 1\n",
    "            nn.BatchNorm2d(128),\n",
    "\n",
    "            nn.Conv2d(128,256,(3,1), padding=0),nn.ReLU(),#64 40 1\n",
    "            nn.Conv2d(256,256,(3,1), padding=0),nn.ReLU(),#64 40 1\n",
    "            nn.MaxPool2d(1,2),                                    #64 20 1\n",
    "            nn.BatchNorm2d(256),\n",
    "\n",
    "            nn.Conv2d(256,512,(3,1), padding=0),nn.ReLU(),#64 40 1\n",
    "            nn.Conv2d(512,512,(3,1), padding=0),nn.ReLU(),#64 40 1\n",
    "            nn.MaxPool2d(1,2),                                    #64 20 1\n",
    "            nn.BatchNorm2d(512),\n",
    "\n",
    "            nn.Conv2d(512,512,(3,1), padding=0),nn.ReLU(),#64 40 1\n",
    "            nn.Conv2d(512,512,(3,1), padding=0),nn.ReLU(),#64 40 1\n",
    "            nn.MaxPool2d(1,2),                                    #64 20 1\n",
    "            nn.BatchNorm2d(512),\n",
    "\n",
    "            nn.Flatten(),\n",
    "\n",
    "            nn.Linear(1024, 256), nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 64), nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(64,6)\n",
    "        )\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x.view([-1,6])\n",
    "\n",
    "    def inferrence(self, x):\n",
    "        x = self.forward(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "qModel = questionNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [64, 16, 158, 1]           1,552\n              ReLU-2           [64, 16, 158, 1]               0\n            Conv2d-3           [64, 16, 156, 1]             784\n              ReLU-4           [64, 16, 156, 1]               0\n            Conv2d-5           [64, 64, 154, 1]           3,136\n              ReLU-6           [64, 64, 154, 1]               0\n         MaxPool2d-7            [64, 64, 77, 1]               0\n       BatchNorm2d-8            [64, 64, 77, 1]             128\n            Conv2d-9           [64, 128, 75, 1]          24,704\n             ReLU-10           [64, 128, 75, 1]               0\n           Conv2d-11           [64, 128, 73, 1]          49,280\n             ReLU-12           [64, 128, 73, 1]               0\n        MaxPool2d-13           [64, 128, 37, 1]               0\n      BatchNorm2d-14           [64, 128, 37, 1]             256\n           Conv2d-15           [64, 256, 35, 1]          98,560\n             ReLU-16           [64, 256, 35, 1]               0\n           Conv2d-17           [64, 256, 33, 1]         196,864\n             ReLU-18           [64, 256, 33, 1]               0\n        MaxPool2d-19           [64, 256, 17, 1]               0\n      BatchNorm2d-20           [64, 256, 17, 1]             512\n           Conv2d-21           [64, 512, 15, 1]         393,728\n             ReLU-22           [64, 512, 15, 1]               0\n           Conv2d-23           [64, 512, 13, 1]         786,944\n             ReLU-24           [64, 512, 13, 1]               0\n        MaxPool2d-25            [64, 512, 7, 1]               0\n      BatchNorm2d-26            [64, 512, 7, 1]           1,024\n           Conv2d-27            [64, 512, 5, 1]         786,944\n             ReLU-28            [64, 512, 5, 1]               0\n           Conv2d-29            [64, 512, 3, 1]         786,944\n             ReLU-30            [64, 512, 3, 1]               0\n        MaxPool2d-31            [64, 512, 2, 1]               0\n      BatchNorm2d-32            [64, 512, 2, 1]           1,024\n          Flatten-33                 [64, 1024]               0\n           Linear-34                  [64, 256]         262,400\n             ReLU-35                  [64, 256]               0\n          Dropout-36                  [64, 256]               0\n           Linear-37                   [64, 64]          16,448\n             ReLU-38                   [64, 64]               0\n          Dropout-39                   [64, 64]               0\n           Linear-40                    [64, 6]             390\n================================================================\nTotal params: 3,411,622\nTrainable params: 3,411,622\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 1.25\nForward/backward pass size (MB): 87.19\nParams size (MB): 13.01\nEstimated Total Size (MB): 101.45\n----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary_(qModel,(1,160,32),batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs=1, lr = learning_rate):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        print('\\nEpoch: %d' % (epoch+1))\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            image, label = data\n",
    "            # Grad initialization\n",
    "            optimizer.zero_grad()\n",
    "            # Forward propagation\n",
    "            output = model(image)\n",
    "            # Calculate loss\n",
    "            \n",
    "            #print(Variable(index).type(torch.LongTensor))\n",
    "            loss = criterion(output, label)\n",
    "            # Backprop\n",
    "            loss.backward()\n",
    "            # Weight update\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _,predicted = output.max(1)\n",
    "            total += label.size(0)\n",
    "            correct += predicted.eq(label).sum().item()\n",
    "\n",
    "            if (batch_idx+1) % 100 == 0:\n",
    "                print(\"Step: {}/{} | train_loss: {:.4f} | Acc:{:.3f}%\".format(batch_idx+1, len(train_loader), train_loss/1000, 100.*correct/total), \"-----> \", end = \"\")\n",
    "                test_model(model)\n",
    "\n",
    "def test_model(model):\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    total=0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            question, label = data\n",
    "            output = model(question)\n",
    "            loss = criterion(output,label)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _,predicted = output.max(1)\n",
    "            total += label.size(0)\n",
    "            correct += predicted.eq(label).sum().item()\n",
    "            \n",
    "            if(batch_idx+1) == len(test_loader):\n",
    "                print(\"Test_loss: {:.4f} | Test_Acc:{:.3f}%\".format(test_loss/1000, 100.*correct/total))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Step: 100/731 | train_loss: 0.1718 | Acc:26.609% -----> Test_loss: 0.2761 | Test_Acc:36.500%\n",
      "Step: 200/731 | train_loss: 0.3104 | Acc:34.469% -----> Test_loss: 0.2364 | Test_Acc:47.625%\n",
      "Step: 300/731 | train_loss: 0.4323 | Acc:39.964% -----> Test_loss: 0.2083 | Test_Acc:54.882%\n",
      "Step: 400/731 | train_loss: 0.5447 | Acc:43.926% -----> Test_loss: 0.1934 | Test_Acc:58.391%\n",
      "Step: 500/731 | train_loss: 0.6452 | Acc:47.378% -----> Test_loss: 0.1775 | Test_Acc:62.208%\n",
      "Step: 600/731 | train_loss: 0.7414 | Acc:49.901% -----> Test_loss: 0.1701 | Test_Acc:63.714%\n",
      "Step: 700/731 | train_loss: 0.8332 | Acc:52.013% -----> Test_loss: 0.1600 | Test_Acc:65.691%\n",
      "\n",
      "Epoch: 2\n",
      "Step: 100/731 | train_loss: 0.0869 | Acc:67.641% -----> Test_loss: 0.1653 | Test_Acc:64.228%\n",
      "Step: 200/731 | train_loss: 0.1729 | Acc:67.867% -----> Test_loss: 0.1504 | Test_Acc:69.491%\n",
      "Step: 300/731 | train_loss: 0.2565 | Acc:68.484% -----> Test_loss: 0.1478 | Test_Acc:69.833%\n",
      "Step: 400/731 | train_loss: 0.3358 | Acc:68.992% -----> Test_loss: 0.1477 | Test_Acc:71.245%\n",
      "Step: 500/731 | train_loss: 0.4151 | Acc:69.641% -----> Test_loss: 0.1402 | Test_Acc:73.214%\n",
      "Step: 600/731 | train_loss: 0.4895 | Acc:70.401% -----> Test_loss: 0.1394 | Test_Acc:74.446%\n",
      "Step: 700/731 | train_loss: 0.5626 | Acc:71.025% -----> Test_loss: 0.1343 | Test_Acc:74.369%\n",
      "\n",
      "Epoch: 3\n",
      "Step: 100/731 | train_loss: 0.0700 | Acc:77.016% -----> Test_loss: 0.1295 | Test_Acc:76.046%\n",
      "Step: 200/731 | train_loss: 0.1399 | Acc:76.555% -----> Test_loss: 0.1329 | Test_Acc:75.866%\n",
      "Step: 300/731 | train_loss: 0.2073 | Acc:76.948% -----> Test_loss: 0.1244 | Test_Acc:77.595%\n",
      "Step: 400/731 | train_loss: 0.2776 | Acc:76.902% -----> Test_loss: 0.1255 | Test_Acc:77.647%\n",
      "Step: 500/731 | train_loss: 0.3449 | Acc:77.100% -----> Test_loss: 0.1230 | Test_Acc:77.775%\n",
      "Step: 600/731 | train_loss: 0.4102 | Acc:77.385% -----> Test_loss: 0.1208 | Test_Acc:78.323%\n",
      "Step: 700/731 | train_loss: 0.4736 | Acc:77.723% -----> Test_loss: 0.1261 | Test_Acc:77.356%\n",
      "\n",
      "Epoch: 4\n",
      "Step: 100/731 | train_loss: 0.0627 | Acc:79.922% -----> Test_loss: 0.1258 | Test_Acc:77.390%\n",
      "Step: 200/731 | train_loss: 0.1245 | Acc:79.773% -----> Test_loss: 0.1134 | Test_Acc:80.941%\n",
      "Step: 300/731 | train_loss: 0.1862 | Acc:79.958% -----> Test_loss: 0.1119 | Test_Acc:80.659%\n",
      "Step: 400/731 | train_loss: 0.2466 | Acc:80.242% -----> Test_loss: 0.1135 | Test_Acc:79.572%\n",
      "Step: 500/731 | train_loss: 0.3098 | Acc:80.247% -----> Test_loss: 0.1086 | Test_Acc:81.095%\n",
      "Step: 600/731 | train_loss: 0.3701 | Acc:80.299% -----> Test_loss: 0.1114 | Test_Acc:80.881%\n",
      "Step: 700/731 | train_loss: 0.4290 | Acc:80.475% -----> Test_loss: 0.1058 | Test_Acc:80.565%\n",
      "\n",
      "Epoch: 5\n",
      "Step: 100/731 | train_loss: 0.0583 | Acc:81.078% -----> Test_loss: 0.1103 | Test_Acc:81.198%\n",
      "Step: 200/731 | train_loss: 0.1164 | Acc:81.586% -----> Test_loss: 0.1059 | Test_Acc:82.062%\n",
      "Step: 300/731 | train_loss: 0.1753 | Acc:81.651% -----> Test_loss: 0.1065 | Test_Acc:81.908%\n",
      "Step: 400/731 | train_loss: 0.2291 | Acc:81.953% -----> Test_loss: 0.1006 | Test_Acc:82.011%\n",
      "Step: 500/731 | train_loss: 0.2837 | Acc:82.069% -----> Test_loss: 0.1085 | Test_Acc:80.933%\n",
      "Step: 600/731 | train_loss: 0.3379 | Acc:82.190% -----> Test_loss: 0.1106 | Test_Acc:81.968%\n",
      "Step: 700/731 | train_loss: 0.3931 | Acc:82.306% -----> Test_loss: 0.0998 | Test_Acc:82.542%\n",
      "\n",
      "Epoch: 6\n",
      "Step: 100/731 | train_loss: 0.0527 | Acc:82.719% -----> Test_loss: 0.1020 | Test_Acc:82.901%\n",
      "Step: 200/731 | train_loss: 0.1149 | Acc:81.500% -----> Test_loss: 0.1085 | Test_Acc:81.095%\n",
      "Step: 300/731 | train_loss: 0.1704 | Acc:81.911% -----> Test_loss: 0.1036 | Test_Acc:82.336%\n",
      "Step: 400/731 | train_loss: 0.2221 | Acc:82.332% -----> Test_loss: 0.0984 | Test_Acc:82.927%\n",
      "Step: 500/731 | train_loss: 0.2736 | Acc:82.556% -----> Test_loss: 0.1024 | Test_Acc:82.242%\n",
      "Step: 600/731 | train_loss: 0.3262 | Acc:82.714% -----> Test_loss: 0.0995 | Test_Acc:82.559%\n",
      "Step: 700/731 | train_loss: 0.3788 | Acc:82.799% -----> Test_loss: 0.1122 | Test_Acc:80.907%\n",
      "\n",
      "Epoch: 7\n",
      "Step: 100/731 | train_loss: 0.0506 | Acc:83.547% -----> Test_loss: 0.1017 | Test_Acc:82.816%\n",
      "Step: 200/731 | train_loss: 0.1007 | Acc:83.625% -----> Test_loss: 0.0960 | Test_Acc:83.415%\n",
      "Step: 300/731 | train_loss: 0.1507 | Acc:83.708% -----> Test_loss: 0.1004 | Test_Acc:82.816%\n",
      "Step: 400/731 | train_loss: 0.2007 | Acc:83.828% -----> Test_loss: 0.0938 | Test_Acc:83.671%\n",
      "Step: 500/731 | train_loss: 0.2503 | Acc:83.987% -----> Test_loss: 0.0959 | Test_Acc:83.038%\n",
      "Step: 600/731 | train_loss: 0.2993 | Acc:84.034% -----> Test_loss: 0.0912 | Test_Acc:83.825%\n",
      "Step: 700/731 | train_loss: 0.3464 | Acc:84.203% -----> Test_loss: 0.0951 | Test_Acc:83.740%\n",
      "\n",
      "Epoch: 8\n",
      "Step: 100/731 | train_loss: 0.0453 | Acc:85.312% -----> Test_loss: 0.0905 | Test_Acc:84.005%\n",
      "Step: 200/731 | train_loss: 0.0916 | Acc:85.164% -----> Test_loss: 0.0936 | Test_Acc:83.483%\n",
      "Step: 300/731 | train_loss: 0.1439 | Acc:84.552% -----> Test_loss: 0.0976 | Test_Acc:82.644%\n",
      "Step: 400/731 | train_loss: 0.1905 | Acc:84.527% -----> Test_loss: 0.0912 | Test_Acc:84.407%\n",
      "Step: 500/731 | train_loss: 0.2358 | Acc:84.688% -----> Test_loss: 0.0894 | Test_Acc:84.561%\n",
      "Step: 600/731 | train_loss: 0.2808 | Acc:84.844% -----> Test_loss: 0.0885 | Test_Acc:84.082%\n",
      "Step: 700/731 | train_loss: 0.3267 | Acc:84.917% -----> Test_loss: 0.0892 | Test_Acc:84.022%\n",
      "\n",
      "Epoch: 9\n",
      "Step: 100/731 | train_loss: 0.0430 | Acc:86.203% -----> Test_loss: 0.0898 | Test_Acc:83.577%\n",
      "Step: 200/731 | train_loss: 0.0876 | Acc:86.039% -----> Test_loss: 0.0936 | Test_Acc:83.808%\n",
      "Step: 300/731 | train_loss: 0.1333 | Acc:85.885% -----> Test_loss: 0.0920 | Test_Acc:83.671%\n",
      "Step: 400/731 | train_loss: 0.1773 | Acc:85.891% -----> Test_loss: 0.0934 | Test_Acc:83.680%\n",
      "Step: 500/731 | train_loss: 0.2200 | Acc:86.037% -----> Test_loss: 0.0907 | Test_Acc:84.407%\n",
      "Step: 600/731 | train_loss: 0.2636 | Acc:86.042% -----> Test_loss: 0.0893 | Test_Acc:84.921%\n",
      "Step: 700/731 | train_loss: 0.3066 | Acc:86.123% -----> Test_loss: 0.0862 | Test_Acc:84.912%\n",
      "\n",
      "Epoch: 10\n",
      "Step: 100/731 | train_loss: 0.0418 | Acc:86.609% -----> Test_loss: 0.0883 | Test_Acc:84.690%\n",
      "Step: 200/731 | train_loss: 0.0853 | Acc:86.016% -----> Test_loss: 0.0944 | Test_Acc:83.671%\n",
      "Step: 300/731 | train_loss: 0.1285 | Acc:86.104% -----> Test_loss: 0.0888 | Test_Acc:84.733%\n",
      "Step: 400/731 | train_loss: 0.1716 | Acc:86.113% -----> Test_loss: 0.0860 | Test_Acc:85.220%\n",
      "Step: 500/731 | train_loss: 0.2140 | Acc:86.159% -----> Test_loss: 0.0872 | Test_Acc:84.365%\n",
      "Step: 600/731 | train_loss: 0.2566 | Acc:86.190% -----> Test_loss: 0.0877 | Test_Acc:84.681%\n",
      "Step: 700/731 | train_loss: 0.2993 | Acc:86.176% -----> Test_loss: 0.0847 | Test_Acc:85.143%\n"
     ]
    }
   ],
   "source": [
    "train_model(qModel, num_epochs = 10)"
   ]
  },
  {
   "source": [
    "model save and load"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test_loss: 0.0908 | Test_Acc:84.082%\n"
     ]
    }
   ],
   "source": [
    "test_model(qModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(qModel.state_dict(), \"./trainedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "model = questionNet()\n",
    "model.load_state_dict(torch.load(\"./trainedModel\"))"
   ]
  },
  {
   "source": [
    "question type inferrence using model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexToString(modelOutput):\n",
    "    if modelOutput == 0:\n",
    "        return \"기하와벡터\"\n",
    "    elif modelOutput == 1:\n",
    "        return \"미적분1\"\n",
    "    elif modelOutput == 2:\n",
    "        return \"미적분2\"\n",
    "    elif modelOutput == 3:\n",
    "        return \"수학1\"\n",
    "    elif modelOutput == 4:\n",
    "        return \"수학2\"\n",
    "    elif modelOutput == 5:\n",
    "        return \"확률과통계\"\n",
    "\n",
    "def getTypeOfQuestion(question, model):\n",
    "    model.eval()\n",
    "    questionToTensor = torch.Tensor(embedAndFitQuestion(tokenizer, wordEmbedder, question, embeddingSize, 160))\n",
    "    modelOutput = model.inferrence(questionToTensor.view([1,1,160,32]))\n",
    "    return indexToString(modelOutput.argmax().item()), modelOutput[0][modelOutput.argmax().item()].item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "question:  두 사건  ,  에 대하여 P, P, PP 일 때, P∩의 값은?\n분류 결과:  확률과통계 , 신뢰도:  90.9182608127594 %\n\nquestion:  정규분포 N 을 따르는 모집단에서 크기가 인 표본을 임의추출하여 구한 표본평균을  라 할 때, E  의 값은?\n분류 결과:  확률과통계 , 신뢰도:  99.66621398925781 %\n\nquestion:  곡선    과  축 및 두 직선   ln  ,   ln  로 둘러싸인 부분의 넓이는?\n분류 결과:  미적분2 , 신뢰도:  99.75231289863586 %\n\nquestion:  수열 은  이고, 모든 자연수 에 대하여 다음 조건을 만족시킨다. ( 가 )       ×     (나)  × 일때,  의값은?\n분류 결과:  수학2 , 신뢰도:  89.8624062538147 %\n\nquestion:  최고차항의 계수가 인 삼차함수 에 대하여 실수 전체의 집합에서 정의된 함수 sin가 다음 조건을 만족시킨다. (가) 에서 함수 가 극대가 되는 의 개수가 이고, 이때 극댓값이 모두 동일하다. (나) 함수 의 최댓값은  이고 최솟값은 이다.           일 때 ,      의 값 을 구 하 시 오 . ( 단 ,  와  는 유리수이다.)\n분류 결과:  미적분2 , 신뢰도:  84.33175086975098 %\n\nquestion:  숫자 , , , , 가 하나씩 적힌 개의 공이 들어 있는 주머니가 있다. 이 주머니와 한 개의 주사위를 사용하여 다음 규칙에 따라 점수를 얻는 시행을 한다. 주머니에서 임의로 한 개의 공을 꺼내어 꺼낸 공에 적힌 수가 이면 주사위를 번 던져서 나오는 세 눈의 수의 합을 점수로 하고, 꺼낸 공에 적힌 수가 이면 주사위를 번 던져서 나오는 네 눈의 수의 합을 점수로 한다. 이시행을한번하여얻은점수가점일확률은 이다.   의 값을 구하시오. (단, 와 는 서로소인 자연수이다.)\n분류 결과:  확률과통계 , 신뢰도:  99.11876916885376 %\n\nquestion:  함수 는 최고차항의 계수가 인 삼차함수이고, 함수 는 일차함수이다. 함수 를               ≥ 이라 하자. 함수 가 실수 전체의 집합에서 미분가능하고, , 일 때, 의 값을 구하시오.\n분류 결과:  수학2 , 신뢰도:  74.49702024459839 %\n\n"
     ]
    }
   ],
   "source": [
    "questionList = list()\n",
    "#2021 수능 수학 가형 4번\n",
    "questionList.append(\"두 사건  ,  에 대하여 P, P, PP 일 때, P∩의 값은?\")\n",
    "\n",
    "#2021 수능 수학 가형 6번\n",
    "questionList.append(\"정규분포 N 을 따르는 모집단에서 크기가 인 표본을 임의추출하여 구한 표본평균을  라 할 때, E  의 값은?\")\n",
    "\n",
    "#2021 수능 수학 가형 8번\n",
    "questionList.append(\"곡선    과  축 및 두 직선   ln  ,   ln  로 둘러싸인 부분의 넓이는?\")\n",
    "\n",
    "#2021 수능 수학 가형 21번\n",
    "questionList.append(\"수열 은  이고, 모든 자연수 에 대하여 다음 조건을 만족시킨다. ( 가 )       ×     (나)  × 일때,  의값은?\")\n",
    "\n",
    "#2021 수능 수학 가형 30번\n",
    "questionList.append(\"최고차항의 계수가 인 삼차함수 에 대하여 실수 전체의 집합에서 정의된 함수 sin가 다음 조건을 만족시킨다. (가) 에서 함수 가 극대가 되는 의 개수가 이고, 이때 극댓값이 모두 동일하다. (나) 함수 의 최댓값은  이고 최솟값은 이다.           일 때 ,      의 값 을 구 하 시 오 . ( 단 ,  와  는 유리수이다.)\")\n",
    "\n",
    "#2021 수능 수학 나형 29번\n",
    "questionList.append(\"숫자 , , , , 가 하나씩 적힌 개의 공이 들어 있는 주머니가 있다. 이 주머니와 한 개의 주사위를 사용하여 다음 규칙에 따라 점수를 얻는 시행을 한다. 주머니에서 임의로 한 개의 공을 꺼내어 꺼낸 공에 적힌 수가 이면 주사위를 번 던져서 나오는 세 눈의 수의 합을 점수로 하고, 꺼낸 공에 적힌 수가 이면 주사위를 번 던져서 나오는 네 눈의 수의 합을 점수로 한다. 이시행을한번하여얻은점수가점일확률은 이다.   의 값을 구하시오. (단, 와 는 서로소인 자연수이다.)\")\n",
    "\n",
    "#2021 수능 수학 나형 30번\n",
    "questionList.append(\"함수 는 최고차항의 계수가 인 삼차함수이고, 함수 는 일차함수이다. 함수 를               ≥ 이라 하자. 함수 가 실수 전체의 집합에서 미분가능하고, , 일 때, 의 값을 구하시오.\")\n",
    "\n",
    "for question in questionList:\n",
    "    classificationResult = getTypeOfQuestion(question, model)\n",
    "    print(\"question: \", question)\n",
    "    print(\"분류 결과: \", classificationResult[0], \", 신뢰도: \", classificationResult[1], \"%\")\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6fb88c66d3fc525dcdf6c0db0ace19818a1a9c38c89901987dbb2dffcb75e87a"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}